
@article{larsson_off-line_2000,
	title = {Off-line dictionary-based compression},
	volume = {88},
	issn = {1558-2256},
	doi = {10.1109/5.892708},
	abstract = {Dictionary-based modeling is a mechanism used in many practical compression schemes. In most implementations of dictionary-based compression the encoder operates on-line, incrementally inferring its dictionary of available phrases from previous parts of the message. An alternative approach is to use the full message to infer a complete dictionary in advance, and include an explicit representation of the dictionary as part of the compressed message. In this investigation, we develop a compression scheme that is a combination of a simple but powerful phrase derivation method and a compact dictionary encoding. The scheme is highly efficient, particularly in decompression, and has characteristics that make it a favorable choice when compressed data is to be searched directly. We describe data structures and algorithms that allow our mechanism to operate in linear time and space.},
	pages = {1722--1732},
	number = {11},
	journaltitle = {Proceedings of the {IEEE}},
	author = {Larsson, N. J. and Moffat, A.},
	date = {2000-11},
	note = {Conference Name: Proceedings of the {IEEE}},
	keywords = {\_read, Australia Council, available phrases, compact dictionary encoding, compressed message, Computer science, data compression, Data compression, data structures, Data structures, Decoding, decompression, Dictionaries, Encoding, entropy codes, grammars, linear space, linear time, off-line dictionary-based compression, phrase derivation method, Resource management, Software engineering},
	file = {IEEE Xplore Abstract Record:/home/skadic/Zotero/storage/2FLJY2HT/892708.html:text/html;IEEE Xplore Full Text PDF:/home/skadic/Zotero/storage/UHB99VC4/Larsson und Moffat - 2000 - Off-line dictionary-based compression.pdf:application/pdf},
}

@article{nevill-manning_identifying_1997,
	title = {Identifying Hierarchical Structure in Sequences: A linear-time algorithm},
	url = {http://arxiv.org/abs/cs/9709102},
	shorttitle = {Identifying Hierarchical Structure in Sequences},
	abstract = {{SEQUITUR} is an algorithm that infers a hierarchical structure from a sequence of discrete symbols by replacing repeated phrases with a grammatical rule that generates the phrase, and continuing this process recursively. The result is a hierarchical representation of the original sequence, which offers insights into its lexical structure. The algorithm is driven by two constraints that reduce the size of the grammar, and produce structure as a by-product. {SEQUITUR} breaks new ground by operating incrementally. Moreover, the method's simple structure permits a proof that it operates in space and time that is linear in the size of the input. Our implementation can process 50,000 symbols per second and has been applied to an extensive range of real world sequences.},
	journaltitle = {{arXiv}:cs/9709102},
	author = {Nevill-Manning, C. G. and Witten, I. H.},
	urldate = {2020-12-07},
	date = {1997-08-31},
	eprinttype = {arxiv},
	eprint = {cs/9709102},
	keywords = {\_read, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/skadic/Zotero/storage/7V9IUA7V/Nevill-Manning und Witten - 1997 - Identifying Hierarchical Structure in Sequences A.pdf:application/pdf;arXiv.org Snapshot:/home/skadic/Zotero/storage/FVY2HI4C/9709102.html:text/html},
}

@inproceedings{benz_effective_2013,
	location = {New York, {NY}, {USA}},
	title = {An effective heuristic for the smallest grammar problem},
	isbn = {978-1-4503-1963-8},
	url = {https://doi.org/10.1145/2463372.2463441},
	doi = {10.1145/2463372.2463441},
	series = {{GECCO} '13},
	abstract = {The smallest grammar problem is the problem of finding the smallest context-free grammar that generates exactly one given sequence. Approximating the problem with a ratio of less than 8569/8568 is known to be {NP}-hard. Most work on this problem has focused on finding decent solutions fast (mostly in linear time), rather than on good heuristic algorithms. Inspired by a new perspective on the problem presented by Carrascosa et al.{\textbackslash} (2010), we investigate the performance of different heuristics on the problem. The aim is to find a good solution on large instances by allowing more than linear time. We propose a hybrid of a max-min ant system and a genetic algorithm that in combination with a novel local search outperforms the state of the art on all files of the Canterbury corpus, a standard benchmark suite. Furthermore, this hybrid performs well on a standard {DNA} corpus.},
	pages = {487--494},
	booktitle = {Proceedings of the 15th annual conference on Genetic and evolutionary computation},
	publisher = {Association for Computing Machinery},
	author = {Benz, Florian and Kötzing, Timo},
	urldate = {2020-12-10},
	date = {2013-07-06},
	keywords = {ant colony optimization, evolutionary computation, smallest grammar problem},
	file = {Full Text PDF:/home/skadic/Zotero/storage/FCI8ESJ2/Benz und Kötzing - 2013 - An effective heuristic for the smallest grammar pr.pdf:application/pdf},
}

@article{belazzougui_block_2021,
	title = {Block trees},
	volume = {117},
	issn = {0022-0000},
	url = {https://www.sciencedirect.com/science/article/pii/S0022000020301033},
	doi = {10.1016/j.jcss.2020.11.002},
	abstract = {Let string S[1..n] be parsed into z phrases by the Lempel-Ziv algorithm. The corresponding compression algorithm encodes S in O(z) space, but it does not support random access to S. We introduce a data structure, the block tree, that represents S in O(zlog⁡(n/z)) space and extracts any symbol of S in time O(log⁡(n/z)), among other space-time tradeoffs. The structure also supports other queries that are useful for building compressed data structures on top of S. Further, block trees can be built in linear time and in a scalable manner. Our experiments show that block trees offer relevant space-time tradeoffs compared to other compressed string representations for highly repetitive strings.},
	pages = {1--22},
	journaltitle = {Journal of Computer and System Sciences},
	shortjournal = {Journal of Computer and System Sciences},
	author = {Belazzougui, Djamal and Cáceres, Manuel and Gagie, Travis and Gawrychowski, Paweł and Kärkkäinen, Juha and Navarro, Gonzalo and Ordóñez, Alberto and Puglisi, Simon J. and Tabei, Yasuo},
	urldate = {2022-11-25},
	date = {2021-05-01},
	langid = {english},
	keywords = {Compressed data structures, Lempel-Ziv compression, Repetitive string collections},
	file = {Belazzougui et al. - 2021 - Block trees.pdf:/home/skadic/Zotero/storage/TIKV85FT/Belazzougui et al. - 2021 - Block trees.pdf:application/pdf;ScienceDirect Snapshot:/home/skadic/Zotero/storage/5GM85RU9/S0022000020301033.html:text/html},
}

@misc{ideue_approximation_2021,
	title = {On the approximation ratio of {LZ}-End to {LZ}77},
	url = {http://arxiv.org/abs/2106.01173},
	abstract = {A family of Lempel-Ziv factorizations is a well-studied string structure. The {LZ}-End factorization is a member of the family that achieved faster extraction of any substrings (Kreft \& Navarro, {TCS} 2013). One of the interests for {LZ}-End factorizations is the possible diﬀerence between the size of {LZ}-End and {LZ}77 factorizations. They also showed families of strings where the approximation ratio of the number of {LZ}-End phrases to the number of {LZ}77 phrases asymptotically approaches 2. However, the alphabet size of these strings is unbounded. In this paper, we analyze the {LZ}-End factorization of the period-doubling sequence. We also show that the approximation ratio for the period-doubling sequence asymptotically approaches 2 for the binary alphabet.},
	number = {{arXiv}:2106.01173},
	publisher = {{arXiv}},
	author = {Ideue, Takumi and Mieno, Takuya and Funakoshi, Mitsuru and Nakashima, Yuto and Inenaga, Shunsuke and Takeda, Masayuki},
	urldate = {2022-11-25},
	date = {2021-08-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2106.01173 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Discrete Mathematics},
	file = {Ideue et al. - 2021 - On the approximation ratio of LZ-End to LZ77.pdf:/home/skadic/Zotero/storage/CMCBR2Z4/Ideue et al. - 2021 - On the approximation ratio of LZ-End to LZ77.pdf:application/pdf},
}

@misc{kreft_self-index_2011,
	title = {Self-Index Based on {LZ}77},
	url = {http://arxiv.org/abs/1101.4065},
	doi = {10.48550/arXiv.1101.4065},
	abstract = {We introduce the first self-index based on the Lempel-Ziv 1977 compression format ({LZ}77). It is particularly competitive for highly repetitive text collections such as sequence databases of genomes of related species, software repositories, versioned document collections, and temporal text databases. Such collections are extremely compressible but classical self-indexes fail to capture that source of compressibility. Our self-index takes in practice a few times the space of the text compressed with {LZ}77 (as little as 2.6 times), extracts 1--2 million characters of the text per second, and finds patterns at a rate of 10--50 microseconds per occurrence. It is smaller (up to one half) than the best current self-index for repetitive collections, and faster in many cases.},
	number = {{arXiv}:1101.4065},
	publisher = {{arXiv}},
	author = {Kreft, Sebastian and Navarro, Gonzalo},
	urldate = {2023-02-10},
	date = {2011-01-20},
	eprinttype = {arxiv},
	eprint = {1101.4065 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {arXiv Fulltext PDF:/home/skadic/Zotero/storage/YERRQ6QP/Kreft and Navarro - 2011 - Self-Index Based on LZ77.pdf:application/pdf;arXiv.org Snapshot:/home/skadic/Zotero/storage/YE6RSGSY/1101.html:text/html},
}

@misc{bille_random_2013,
	title = {Random Access to Grammar Compressed Strings},
	url = {http://arxiv.org/abs/1001.1565},
	doi = {10.48550/arXiv.1001.1565},
	abstract = {Grammar based compression, where one replaces a long string by a small context-free grammar that generates the string, is a simple and powerful paradigm that captures many popular compression schemes. In this paper, we present a novel grammar representation that allows efficient random access to any character or substring without decompressing the string. Let \$S\$ be a string of length \$N\$ compressed into a context-free grammar \${\textbackslash}mathcal\{S\}\$ of size \$n\$. We present two representations of \${\textbackslash}mathcal\{S\}\$ achieving \$O({\textbackslash}log N)\$ random access time, and either \$O(n{\textbackslash}cdot {\textbackslash}alpha\_k(n))\$ construction time and space on the pointer machine model, or \$O(n)\$ construction time and space on the {RAM}. Here, \${\textbackslash}alpha\_k(n)\$ is the inverse of the \$k{\textasciicircum}\{th\}\$ row of Ackermann's function. Our representations also efficiently support decompression of any substring in \$S\$: we can decompress any substring of length \$m\$ in the same complexity as a single random access query and additional \$O(m)\$ time. Combining these results with fast algorithms for uncompressed approximate string matching leads to several efficient algorithms for approximate string matching on grammar-compressed strings without decompression. For instance, we can find all approximate occurrences of a pattern \$P\$ with at most \$k\$ errors in time \$O(n({\textbackslash}min{\textbackslash}\{{\textbar}P{\textbar}k, k{\textasciicircum}4 + {\textbar}P{\textbar}{\textbackslash}\} + {\textbackslash}log N) + occ)\$, where \$occ\$ is the number of occurrences of \$P\$ in \$S\$. Finally, we generalize our results to navigation and other operations on grammar-compressed ordered trees. All of the above bounds significantly improve the currently best known results. To achieve these bounds, we introduce several new techniques and data structures of independent interest, including a predecessor data structure, two "biased" weighted ancestor data structures, and a compact representation of heavy paths in grammars.},
	number = {{arXiv}:1001.1565},
	publisher = {{arXiv}},
	author = {Bille, Philip and Landau, Gad M. and Raman, Rajeev and Sadakane, Kunihiko and Satti, Srinivasa Rao and Weimann, Oren},
	urldate = {2023-02-10},
	date = {2013-10-29},
	eprinttype = {arxiv},
	eprint = {1001.1565 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {arXiv Fulltext PDF:/home/skadic/Zotero/storage/RMT46Y8C/Bille et al. - 2013 - Random Access to Grammar Compressed Strings.pdf:application/pdf;arXiv.org Snapshot:/home/skadic/Zotero/storage/4ZE7KIVA/1001.html:text/html},
}

@article{nunes_grammar_2022,
	title = {Grammar Compression by Induced Suffix Sorting},
	volume = {27},
	issn = {1084-6654, 1084-6654},
	url = {https://dl.acm.org/doi/10.1145/3549992},
	doi = {10.1145/3549992},
	abstract = {A grammar compression algorithm, called {GCIS}, is introduced in this work. {GCIS} is based on the induced suffix sorting algorithm {SAIS}, presented by Nong et al. in 2009. The proposed solution builds on the factorization performed by {SAIS} during suffix sorting. A context-free grammar is used to replace factors by non-terminals. The algorithm is then recursively applied on the shorter sequence of non-terminals. The resulting grammar is encoded by exploiting some redundancies, such as common prefixes between right-hands of rules, sorted according to {SAIS}. {GCIS} excels for its low space and time required for compression while obtaining competitive compression ratios. Our experiments on regular and repetitive, moderate and very large texts, show that {GCIS} stands as a very convenient choice compared to well-known compressors such as Gzip 7-Zip; and {RePair} the gold standard in grammar compression; and recent compressors such as {SOLCA}, {LZRR}, and {LZD}. In exchange, {GCIS} is slow at decompressing. Yet, grammar compressors are more convenient than Lempel-Ziv compressors in that one can access text substrings directly in compressed form without ever decompressing the text. We demonstrate that {GCIS} is an excellent candidate for this scenario, because it shows to be competitive among its {RePair} based alternatives. We also show that the relation with {SAIS} makes {GCIS} a good intermediate structure to build the suffix array and the {LCP} array during decompression of the text.},
	pages = {1--33},
	journaltitle = {{ACM} Journal of Experimental Algorithmics},
	shortjournal = {{ACM} J. Exp. Algorithmics},
	author = {Nunes, Daniel S. N. and Louza, Felipe A. and Gog, Simon and Ayala-Rincón, Mauricio and Navarro, Gonzalo},
	urldate = {2023-02-10},
	date = {2022-12-31},
	langid = {english},
	file = {Full Text PDF:/home/skadic/Zotero/storage/59566VLT/Nunes et al. - 2022 - Grammar Compression by Induced Suffix Sorting.pdf:application/pdf},
}

@article{ziv_universal_1977,
	title = {A universal algorithm for sequential data compression},
	volume = {23},
	issn = {1557-9654},
	doi = {10.1109/TIT.1977.1055714},
	abstract = {A universal algorithm for sequential data compression is presented. Its performance is investigated with respect to a nonprobabilistic model of constrained sources. The compression ratio achieved by the proposed universal code uniformly approaches the lower bounds on the compression ratios attainable by block-to-variable codes and variable-to-block codes designed to match a completely specified source.},
	pages = {337--343},
	number = {3},
	journaltitle = {{IEEE} Transactions on Information Theory},
	author = {Ziv, J. and Lempel, A.},
	date = {1977-05},
	note = {Conference Name: {IEEE} Transactions on Information Theory},
	file = {IEEE Xplore Abstract Record:/home/skadic/Zotero/storage/CIDEGAAF/1055714.html:text/html;IEEE Xplore Full Text PDF:/home/skadic/Zotero/storage/ANWT4BMS/Ziv and Lempel - 1977 - A universal algorithm for sequential data compress.pdf:application/pdf},
}

@inproceedings{kempa_lz-end_2017,
	title = {{LZ}-End Parsing in Compressed Space},
	url = {http://arxiv.org/abs/1611.01769},
	doi = {10.1109/DCC.2017.73},
	abstract = {We present an algorithm that constructs the {LZ}-End parsing (a variation of {LZ}77) of a given string of length \$n\$ in \$O(n{\textbackslash}log{\textbackslash}ell)\$ expected time and \$O(z + {\textbackslash}ell)\$ space, where \$z\$ is the number of phrases in the parsing and \${\textbackslash}ell\$ is the length of the longest phrase. As an option, we can fix \${\textbackslash}ell\$ (e.g., to the size of {RAM}) thus obtaining a reasonable {LZ}-End approximation with the same functionality and the length of phrases restricted by \${\textbackslash}ell\$. This modified algorithm constructs the parsing in streaming fashion in one left to right pass on the input string w.h.p. and performs one right to left pass to verify the correctness of the result. Experimentally comparing this version to other {LZ}77-based analogs, we show that it is of practical interest.},
	pages = {350--359},
	booktitle = {2017 Data Compression Conference ({DCC})},
	author = {Kempa, Dominik and Kosolobov, Dmitry},
	urldate = {2023-02-10},
	date = {2017-04},
	eprinttype = {arxiv},
	eprint = {1611.01769 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {arXiv Fulltext PDF:/home/skadic/Zotero/storage/IPEQQZEI/Kempa and Kosolobov - 2017 - LZ-End Parsing in Compressed Space.pdf:application/pdf;arXiv.org Snapshot:/home/skadic/Zotero/storage/FGQW2DN4/1611.html:text/html},
}

@article{barabash_periodic_2016,
	title = {Periodic words connected with the Fibonacci words},
	volume = {8},
	url = {https://journals.pnu.edu.ua/index.php/cmp/article/view/1409},
	doi = {10.15330/cmp.8.1.11-15},
	abstract = {In this paper we introduce two families of periodic words ({FLP}-words of type 1 and {FLP}-words of type 2) that are connected with the Fibonacci words and investigated their properties.},
	pages = {11--15},
	number = {1},
	journaltitle = {Carpathian Mathematical Publications},
	author = {Barabash, G. M. and Kholyavka, Ya. M. and Tytar, I. V.},
	date = {2016-06},
	file = {BarabashG.M. et al. - 2016 - Periodic words connected with the Fibonacci words.pdf:/home/skadic/Zotero/storage/XBLD6M6I/BarabashG.M. et al. - 2016 - Periodic words connected with the Fibonacci words.pdf:application/pdf},
}
